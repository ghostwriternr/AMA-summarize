STEM vs Lighthouse. Are they close contenders or is stem doomed?
Did you see any examples of VR Direct running on anything?
How close is Virtual Reality to being affordable and, for lack of a better word, mainstream in the average persons every day gaming experience?
With the amazing features announced by Palmer for Unity 5.1 work with DK2 and will the professional version of Unity be required because "Personal Edition does not do betas"?
Is virtuix omni still a joke?
What are your thoughts on the Cyberith Virtualizer? versus the Virtuix Omni?
I believe that absolute positional tracking is critical for a great VR experience. Both systems have this which is great. Although Lighthouse's range and accuracy is impressive, it's reliant on line-of-sight. STEM doesn't have the same range (though I don't believe we've seen their long-range mode demonstrated yet), but they aren't reliant on line-of-sight.  When you look at the tracking options available, there doesn't seem to be a one-size-fits-all answer to tracking in VR. Lighthouse will work well for many things, STEM still has some advantages. And importantly, we don't know the cost of Lighthouse which will likely be a huge factor for most users.
Hi Ben.  Were you able to get any sense of the current relationship between Valve and OVR from the employees you had talked to over the conference?
Not yet, it seems to still be in the development phase. Nvidia held a GDC session which addressed VR Direct... directly. AMD and Valve also held sessions about optimized VR rengering.  Nvidia's VR Direct session was fairly technical, but we did a [liveblog of it here](http://www.roadtovr.com/vr-direct-how-nvidia-technology-is-improving-the-vr-experience-live-blog-2pm-pst/), and hopefully it will pop up on video soon when GDC releases it.
I am deeply impressed with the HTC vive like many here are (without having tried it ofc). But I think all these "Oculus got surpassed" opinions are over the top.  Wouldn't you agree that if Cescent Bay would allow two cameras in the corner of your room (on the ground or right under the ceiling) it would be very quite similar to what the HTC headset is able to achieve? In visual quality they both are similar, some people even reported the Crescent Bay prototype was slightly better in that regard. Tracking resolution and accuracy was never criticized on Crescent Bay.
We've still really only seen dev kit hardware (Gear VR included, according to Oculus), but I don't think anyone in this industry is under the illusion that they can get away with a $1000 minimum entry point for a good VR experience. $500 is likely to be the sweet spot for a system like the Oculus Rift and Morpheus, though we're still waiting patiently to hear how SteamVR will be priced given that it has quite a bit of hardware (headset, two controllers, two positional base stations).
Do you think Valves optical tracking would run into occlusion issues with certain implementations like Sixsenses lightsaber demo for example, where hands and arms may be constantly crossing?
Hi. What is the next big step for improvement of today's VR headsets? Where will the innovations be heading to in the next few years?
I've actually enjoyed my time in the Omni. I haven't played the latest version with a non-native game so I can't comment on what the experience of adapting existing games to it, but the made-for-Virtuix game that I [tried on their latest model at CES 2015](http://www.roadtovr.com/virtuix-omni-preview-production-model-video/) was an enjoyable experience that I've never had elsewhere.
Did you ever try to break the lighthouse tracking through occlusion?
I have only had a chance to try the Omni unfortunately. The Virtualizer's sitting/crouching functionality could be a solid USP. I am prone to think that the Omni's curved surface helps with a more natural gait (it does feel quite good) compared to the Virtualizer's flat surface, but I will really need to try it before I can say for sure. Both companies claim that their particular approach offers the best gait ; ).
Not particularly. I can say that I didn't see any Oculus faces around the Valve booth when I was there, and by the end of GDC, [Carmack said they hadn't yet seen the system](https://twitter.com/ID_AA_Carmack/status/573985052876374019).  Friends or not, they are now direct competitors and that comes with certain baggage. If nothing else, they will certainly be pushing each other to create the best VR experience.
There's no question that Crescent Bay is one of the best VR headsets in the world. Oculus has made incredible progress on the fidelity of tracking, even after the huge jump from the DK1 to the DK2.   It's possible that Oculus could achieve similar range using two cameras, but the IR LEDs are probably may be harder to work with at range given that they don't have the intensity of a laser (as Valve is using in their tracking system). Assuming it could work just as well, Crescent Bay's camera-based tracking has the downside of requiring that the cameras be connected to the PC (and are thus exclusively linked to that PC) whereas Valve's base stations require no link to the PC/headset, only a power outlet. This makes them more practical in my mind to place throughout a home, and it means that any headset walking into that space can be positionally tracked without needing to link up to anything (imagine a mobile VR headset like Gear VR that can become positionally tracked when it is within the Lighthouse tracking volume.   It has been said that Lighthouse's tracking is also computationally less expensive than the computer-vision approach that Oculus is taking with the camera, though I don't know to what extent this is true.
As far as I have seen with the latest headsets, tracking is looming near a 'solved' problem for most use-cases. The next step is field of view (which is both a screen and optics problem) and resolution. Beyond simply cramming more pixels into the same space, companies are likely to investigate new types of display technology that is not raster-based.
Is it true you can pop popcorn kernels just by walking in the Valve demo rooms?
I didn't try particularly beyond waving my arms around like an idiot to make sure I didn't see any jumps in tracking. It passed that test. With two base stations, occlusion seems unlikely, take for some particular actions like trying to hold a virtual shield in front of you which could cause one arm to block the other controller.  When playing I was walking all around within the huge space and tracking held up superbly.
Do they feel natural (or the omni I guess), or do they take a lot of getting used to?  Do you think full vr setups (omni, stem, hmd, 7.1 sound emulation) will be viable (or worth it) in a home environment.  Do you think using an omni can prevent nausea in a fashion similar to valves walking around in a room solution?
Yes it's possible, but the two base station solution makes it seem unlikely. There are IMUs in the controllers as well which could be used to make a good guess on movement if there was an instance of occlusion. The Lighthouse system is also extensible so you could add more base stations for more robustness.
Lets make some bold assumptions for my next question: Oculus was busy behind the scenes and the Rift CV1 will be announced next week and will be in stores around the globe from April, 1st. It is exactly like the Crescent Bay prototype you tried, and of course you will publish an article on this big announcement.  What would be your conclusion: Do you suggest us to get a Rift CV1 or wait 6+ month for RE vive?  (Bonus: I expect the consumer RE vive to have the same specs as the DevKits, but there are people who expect the specs to improve. Whats your opinion on that?)
Even though we don't know a lot about it, what do you think about Google's magic leap?
What do your think about the future of VR in 30 years from now?  the HMD will be very light , the graphics will be utra realistic, and body and hand detection will be perfect? People will be using it on the streets like smartphones as User interfaces with tracked hands  become as easy as touching a phone?
After 5 minutes on the Omni you can walk and run with what feels to be a very natural stride.  Yes, I think the VR experience will be so good in the next few years that people will want an entire space in their home for it. Morpheus will likely be a great choice for those first getting into VR as it will provide a compelling experience with input and you only need a PS4 to play, not a $1200 gaming rig. There's definitely more you can add to the experience (Omni, let's say) but that might start getting into hobbyist territory (like people who have awesome flight sim setups).  Yes I think Omni can prevent nausea because it recreates many of the cues of actually moving through a space. Whenever there is a link between what you are doing in real life and what's happening in the game, it seems to reduce the chance for nausea, even in the case of using a joystick to turn your body instead of having the game do it with no input.
How was the sound on Valve's demos? Did it have the same impact as the 360 soundscape of the Crescent Bay demos? From what I hear and read, their audio is among the best, and seems like many headsets aren't focusing on audio as much, despite it's huge impact on presence.
I'm assuming this is a question about the "frickin' lasers" that Valve is using with their positional tracking system? I didn't feel any heat on my body from the lasers and thus I doubt you'd be able to pop popcorn, unless there's some weird popcorn-laser related physics phenomenon that I'm not aware of...
just trolling, but thanks though ..haha
[deleted]
Isn't the Vive Devkit starting at $300 this spring, like Oculus did?
no dev kits for us simple devs ..Pro devs only (they are only making a couple thousand of them)
Valve is saying holiday 2015 for release of the Vive, in your opinion, do you think Oculus is going to slip into Q1 2016 for the Rift? 
Great questions here. This is like the VR equivalent of the [Trolley Problem](http://en.wikipedia.org/wiki/Trolley_problem)!  It really depends on each person. How much space do you have? How much money are you willing to spend? Is your PC powerful enough?  I will say thisprice/practicality asideA VR experience that allows you to walk naturally and reach into that world with some form of absolutely positioned input is much more immersive than a equivalent experience that lacks the space and input. What Oculus has shown to this point with Crescent Bay is a ~4x4 foot area in which the user can move. That's a few small steps in either direction or one big step. It helps, but the difference between that and really being able to feel like you're strolling from one end of a room to another is huge for immersion. It's possible that CB supports a larger tracking volume than they've shown so far. After all, the DK2's volume alone can be [quite big with the right setup](https://www.youtube.com/watch?v=pjdaozuoxSE)!  Bonus: I've been told by Valve that the dev kit controllers will be wireless even though they were shown as wired at GDC. IIRC the base stations they were using were a slightly older variant than what will ship with the dev kit. So we'll already seeing some improvements from the pre-production dev kit to the dev kit, which leads me to believe that they will be more refinements from dev kit to consumer version. I wouldn't expect the changes to be huge, but I hope they improve the ergonomicswhile Vive isn't bad, it's definitely behind in comfort compared to Crescent Bay and Morpheus.
Hi Ben   Do you agree that VR has created the demand for an affordable motion simulator to be paired with VR and assist with 'Presence'? 
Just to be clear, they are using class 1 lasers, wich are inherently safe, even if you are looking straight into the emitter for an extended period of time. More info: http://en.wikipedia.org/wiki/Laser_safety#Class_1
Standard prediction disclaimer: predicting that far out is almost sure to be useless or too broad to be useful ; )  However, if we look at the progress in the last 3 years alone, I think we can expect much of what you've suggested. It may take a non-raster (pixel-based) display technology to achieve resolution that's equal to the human eye, so I hope we see some developments there. Mobile VR will likely be everywhere at that point, not requiring you to tether to a computer for an amazing VR experience. I hope we'll also see some developments in haptics over the next 30 years, as this is still a huge challenge for VR.
The only source I've seen specifically mentioning a number, states that only 1, 200 units of the Vive Developer Edition will be provided...  &gt; to media and gaming companies and even some universities.  http://www.usatoday.com/story/tech/2015/03/01/htcone-phonemaker-plunges-into-virtual-reality-with-vive/24217607/  Obviously it is unclear if the source is correct. 
What effect do you think VR will have on society as a whole? Is it the "Next" thing?
What do you think about "Motion-Capture Arenas" as a VR arcade option. I saw you wrote an article about our tech way back when and wondered if your mind has changed, or opinion evolved?  Thanks Ben! 
Hi there Ben!  I'm curious; did any of the SteamVR demos feature arms / full body avatar? Or did all of them just have floating virtual hands / controllers?  What about the Morpheus demos?  Thanx!
Not trying to be a stickler here, but I want to clarify: It isn't terribly accurate to call it 'Google's Magic Leap.' Google didn't buy Magic Leap, nor were they the sole investor, though they may have been the lead. Let's step back a moment to catch everyone up:  Magic Leap is working on a wearable AR platform that uses light-fields, which they say will create a much more convincing effect of putting virtual objects into real spaces.  The company raised ~$50 million in their Seed + Series A investments, and then went on to raise a $542 million Series B investment, which had many participants. Because Google was the most notable, many media outlets ran 'Google' in the headline (some even mistakenly reported that Google had bought the company). The reality however is that the Series B investors include: Google, Qualcomm Ventures, Legendary Entertainment, Thomas Tull, KKR, Vulcan Capital, Kleiner Perkins Caufield &amp; Byers, Andreessen Horowitz, Obvious Ventures, and "other investors".  Now that's out of the way ; )  The company has been extremely secretive, but we [did some digging prior to the investment](http://www.roadtovr.com/what-we-know-about-magic-leap-rumored-500m-investment-funding/) which gave us some good clues as to what they'll reveal (which is expected to happen later this year). We expect the final product to be an untethered HMD which doesn't use conventional displays, but instead uses light fields, which essentially sends an image into your eye as though that image really existed in the real world.   Creating accurate imagery is only one half of the problem though. That imagery also has to stay mounted in the environment when you move your head, otherwise it won't feel real. This is likely to become a computer vision problem (analyzing the space around you in an attempt to track it) and it is something I haven't seen done in a compelling way yet. If they solve these two problems, they will have delivered on the promise of a decade of AR concept videos.   
Ben, can you share more about the haptic feedback of the Vive prototype controllers? Valve claims it is good enough to feel the string tension of a bow...
[deleted]
To be honest, I didn't notice the sound being particularly positional or not in the Valve demos, but it very well could be a function of it working so naturally that I didn't even notice ; ). It may have also been because the demos didn't explicitly try to make you notice the positionality of the sound (like having a fluttering pixie fly by your head) I was way too enthralled with the ability to move around the environment, and with checking out the performance of the tracking on the controllers and headset to notice the sound (which is embarrassing for me to say because I consider myself an audio guy!), I will definitely listen carefully next time I'm in the system.  Sony's 2015 Morpheus prototype, on the other hand, demonstrated some really awesome positional sound. There was a scene in ['The London Heist' demo](http://www.roadtovr.com/sony-2015-morpheus-prototype-gdc-2015-hands-on-preview-the-heist/) where a character handed you a cell phone and you held it up to your ear and it sounded like the voice was coming right out of the phone next to you!
Hello Ben :D When is the next Three Bens in VR coming out? Haha, so much to discuss :P  But as an actual VR question, I read VR news like an addict so uh.. hmm... Lately I've been hearing quite a bit of buzz around light fields to display pre-rendered stuff in VR, is that something you've looked into or is that still upcoming tech?
Valve wouldn't give any hint on price, but if they launch a dev kit at $300 it would be a massive value for such a system (assuming we're talking about the headset, controllers, and base stations all in one box). It's possible that the headset could be sold standalone around $300 and the controllers/base stations might be sold separately.
Virtual reality is a powerful thing. I am a researcher and I cannot help but wonder what the effect of patients being not only treated with drugs but virtual reality doses in order to combat depression. Is this a project that you would ever consider? 
I think that as soon as Oculus locks down a release date for the Rift consumer version, they will let us know. For years I've heard complaints about Oculus not giving a release date and seen many supposed release date 'leaks', a simple application of [Occam's razor](http://en.wikipedia.org/wiki/Occam%27s_razor) makes me think that the reason we haven't heard it yet is simply because Oculus hasn't decided themselves ('decided' makes it sound abritrary, but of course it will be dependent on R&amp;D developments and business arrangements coming into place).  It does seem like it would be difficult for Oculus to hit holiday 2015 release given that they haven't announced an input solution (which developers have been expecting to come before the consumer launch), but pressure from Valve (holiday 2015) and Sony (Q2 2016) could make them work a little faster!
I do agree that there is demand, but there's a bit of a paradox at play here: if you make a motion sim too broad, it likely won't work well enough for specific activities, but if you make it too specific, it likely won't see widespread adoption.  Ask any racing sim enthusiast for their dream motion sim and they'll likely tell you something different than a flying sim enthusiast.  I think that the ability to walk around and interact with a virtual space with something like SteamVR is a great broad application of interactivity that will cover many human-based actions and activities. But as soon as you get into vehicles, things get complicated.  That said, I would be absolutely surprised if we don't see someone create a ridiculous [Elite Dangerous sim](https://www.youtube.com/watch?v=PUFIFL7zwXQ) that puts a crazy motion sim in the middle of a motion tracking space, such that they can actually walk around their ship!
Hi Ben,  Curious if you have an insight on using multi-room Lighthouse's. It says line of sight, but do you feel they can be networked together for unusual room configurations?  And do you feel developing for a seated experience is still viable or is it standing only?
Norm from Tested said this about Valve's VR controllers:  &gt; The haptic feedback the controller is also a big deal. Its not just vibrations--the linear actuator motors developed for the Steam Controller can be precise enough to simulate the friction of pulling open a cabinet drawer or the relative tension of a bow string.  I haven't heard anyone else mention this. Maybe it felt so natural that people didn't notice(?) Did you personally notice any haptic feedback apart from the touchpads? Thanks. 
Completely agree I think finding the balance between racing/flight is an essential task not to be overlooked if there's a happy medium in between that's the target. Obviously the price point too.
Books have and will continue to be written on this question.   I hope you will excuse me for not answering your question, but rather than making predictions that have probably been made elsewhere (and explained better), let me tell you what one of my ultimate hopes for VR is.  I hope (beyond the amazing entertainment/educational/business value) that virtual reality will help break down artificial barriers between people. It amazes me that (in the US) we often see political figures on TV decrying the loss of jobs to other countries. "We need to bring jobs home!" they say proudly. But wouldn't bringing jobs home mean a loss of jobs elsewhere? Would that really be an improvement to the overall state of things?  It seems to me that we think this way because of artificial borders and notions of 'us' and '[the other](http://en.wikipedia.org/wiki/Other)', which is a concept I won't dig into here, but essentially we tend to think that people that are near us and/or are associated with us are all part of a group we care about, while people who are far away are unknown are far less important. There are explanations as to why we think this way, but in the end I don't believe that thinking locally is a good idea when our actions have global repercussions.  Anyway... I hope that VR makes it easier to be virtual present with people from around the world. So that we could sit down in our cozy house, pop on a headset, and sit next to someone half way across the world and have them tell us about the unrest that's happening in their country. So that instead of a passing news item, the explosion that killed 10 children in Syria feels like it happened in your own town. I realize that sounds a bit morbid, but the idea is that with that level of realization comes a sense of global responsibility and caring, and it becomes harder for 'us' to look away and be distracted by our own lives which are perfectly fine.   Basically, I hope that VR can overcome our physical limitations of distance and make our global village feel a lot more local. Hippie stuff, I know.
I think the VR arcade was and is still a great idea. Not everyone will have the space/money to dedicate to VR, just like not everyone has the space/money to dedicate to a collection of arcade cabinets! There's also things that would increase the experience, but be impractical to have in your house (this is why movie theaters exist). Those are the kinds of things that would be great in a VR arcade.
Wow... I wasn't expecting such a phenomenal answer. Thank you.   I completely agree- the faster we realize we're a global village ubiquitously seeking the continuity and advancement of society; the better off we'll be to deal with the **real** issues. 
None of the SteamVR demos I saw had avatars, just floating hands or controllers, but I really hope we see them eventually.  One of the Morpheus demos I saw (The London Heist) did indeed have an avatar. When done well, it can be a really cool addition to the experience. Being able to see your own shadow, or wearing a particularly badass outfit, definitely brings you into the world and lets you feel like you are part of the narrative.
Dammit. Maybe I can find one on eBay before the consumer release. :(
The haptic tech in there can create a number of sentations. The 'clicking' feeling under your finger, which can be applied when moving your finger about the trackpad, feels surprisingly localized (as though it happens right under your finger). This is really useful for helping users understand where their finger is on the trackpad (because it can also be displayed in-game) instead of having them feel around a controller for real buttons and then not know which buttons they have landed on.  The haptics can create a variety of sensations from buzzing to clicking. One cool trick I saw used was to buzz one of the controllers which caused me to look down at it to see what caused the buzz. As I did, I could see that there were instructions around my hand, and I raised it up to read them. This was a really neat way to draw my attention to a particular place (a challenge when you are talking about a 360 environment) without pointing a big virtual arrow at it.  I'm willing to bet that if you combined the action of drawing the bowstring with some combination of the buzz/click feedback, it would be very compelling.
Why doesn't Virtuix Omni allow people to actually use their system? They just had VR dudes rotating running through their demo, but yet none of the attendees were allowed to try it out. It just gives me the impression that they have something to hide. Or is it more of a liability issue? I'd love to try it out for myself, but they've been pretty hands off for quite a while.
Hi Ben! Been a long time reader of Road To VR, since the birth of DK1.   - Do you think november will be a feasible release date for Valve (Re)Vive?   - How long before a decent, reasonable priced, mobile VR headset becomes available? I mean, not a lot of people will put 900; down for a VR headset, I think. Google Cardboard is fun, but the tracking is terrible.   - Follow up: I'm working on voxelpaint(.com). Should I port it to GearVR? It's already out for Cardboard.   Cheers!
Sounds pretty exciting. I know a lot of people dismiss the regular controller, I'm wondering how those same people will feel after using it with haptics.
First, I'd like to say thanks for all of the great GDC coverage and articles. I can't be there, so it's nice to know that you guys are.  Question: THe big deal at GDC this year seems to be input. After spending time with Morpheus and Vive, do you think Oculus has a chance to compete if they choose not to include an input solution? Oculus didn't sound too confident about an input solution in recent interviews and with Story Studio and recent demos, they almost seem to be trying to take focus away from input, so it's starting to feel a little like they might be considering launching CV1 without an input solution.
[deleted]
What would you consider to be the best 'full setup'? Meaning the ability to see, hear, move, and interact with the virtual world. What set of equipment? 
Next [Three Bens](http://threebens.libsyn.com/) episode will be out soon. All the Bens got to try all the major VR tech at GDC, and you are right, there is a lot to talk about!  I don't claim to be an expert, but it is something I have looked into. The gist is that a light field display aims to recreate the light that would enter your eye as if it were bouncing off of a real object. If you can do this, you have the basis for making virtual objects appear in the real world that are indistinguishable from real objects (other cues like tracking, lighting aside). It's a compelling idea, but certainly a challenge. For a bit more detail, I'll drop an explanation that I wrote up in a [Magic Leap article](http://www.roadtovr.com/what-we-know-about-magic-leap-rumored-500m-investment-funding/2/) (again not an expert here, and I'd be happy if someone points out any misunderstandings from this text!):  &gt; **Light-fields, Vergence-Accommodation Conflict, and Retina Resolution** &gt;  &gt; In his presentation, Devine mentioned a [*New York Times* article from July](http://www.nytimes.com/2014/07/15/science/taking-real-life-sickness-out-of-virtual-reality.html?_r=0) which talks almost as vaguely about Magic Leap, but at least confirms that the company is working with light-fields. A light-field display could solve the issue of vergence-accommodation conflict thats present in current head mounted displays like the Oculus Rift. &gt;  &gt; Human eyes use two primary means of focusing on objects, vergence and accommodation. Vergence is when both eyes rotate inward to focus at the same point in space; if you cross your eyes, you see double because your eyes dont have the correct vergence on the objects in front of you. The other means of focus is called accommodation, and it happens per-eye, by bending the lens of the eye to focus light from a certain distance onto the retina; if you close one eye and focus on your finger held close to your face, the objects behind it will become out of focus, and vice versa. &gt;  &gt; Vergence and accommodation are thought to be linked, because they work in tandem to give us a focused 3D view of our surroundings. Vergence-accommodation conflict can arise with current VR tech where the vergence is variable, but accommodation is static because the light from objects is always being emitted just inches from your eyes rather than bouncing from actual far away objects. &gt;  &gt; It would seem that Magic Leaps Cinematic Reality technology proposes the use of a head mounted display that uses light-field technology to fix this problem. &gt;  &gt; Modern attempts at near-eye light-field displays involve using micro-lens arrays which take the light from many tiny images and focuses it into a single image. From my understanding, forming the image in this way allows the vergence and accommodation cues to be in sync because the light from virtually distant objects arrives at the eye as though it is really coming from a distant object.
copied and have filed that away.  great answer! 
I believe they've said only one sensor needs to be in sight of either base station (after they've first established the position) for it to work. Or at least that would work for a limited time. So I don't really see occlusion being a problem except in very limited edge cases.
Unfortunately I don't have a good answer for you at this point. We'll have to wait and see : (.  For anyone who is interested in getting into VR development and that might have missed it last week, the two most popular engines for creating Oculus Rift contentUnity and Unreal Engineare now free to download and start using!
Yes the haptics in the steamVR controllers is definitely better than mere rumble. Forgive me for quoting, but I answered a similar question below. If it doesn't fully answer your question just let me know : ).  Although the haptics in the SteamVR controllers is good, I would love to have [Tactical Haptics](http://tacticalhaptics.com/) tech on there as well!  &gt; The haptic tech in there can create a number of sentations. The 'clicking' feeling under your finger, which can be applied when moving your finger about the trackpad, feels surprisingly localized (as though it happens right under your finger). This is really useful for helping users understand where their finger is on the trackpad (because it can also be displayed in-game) instead of having them feel around a controller for real buttons and then not know which buttons they have landed on. &gt;  &gt; The haptics can create a variety of sensations from buzzing to clicking. One cool trick I saw used was to buzz one of the controllers which caused me to look down at it to see what caused the buzz. As I did, I could see that there were instructions around my hand, and I raised it up to read them. This was a really neat way to draw my attention to a particular place (a challenge when you are talking about a 360 environment) without pointing a big virtual arrow at it. &gt;  &gt; I'm willing to bet that if you combined the action of drawing the bowstring with some combination of the buzz/click feedback, it would be very compelling.
It may turn out that caring about the entire world is simply too much for one mind to deal with. The current state of us/other thinking is thought to be an evolutionary trait, but it might also have a fundamental constraint due to brain structure. However, I would suspect that we can counter this as we become more organized with technology.
Hey man. Just wanted to say Great Job! I met you at Oculus Connect and you're definitely a class act.   Is Road to VR a full time gig for you? Or is it something you do on the side?
The controller is only 'regular' in the sense that it has buttons ; ). The ability to reach out and 'grab' something (even if the grabbing part happens with a button press) is transformative in terms of user interaction and is going to make games so much more exciting and easier to play!  The cool think about Lighthouse is that it should be easily extensible, for those of us who might want to really hold a bat/gun/sword shaped controller.
Have you tried 3dhead? Is it really just a big joke, or what? 
I think VR has many applications here. From being able to see a therapist easily, confidentially, and remotely, to virtual therapy experiences. There's even well-being applications for those that don't need medical attention, like [relaxation environments](http://www.roadtovr.com/guided-meditation-proves-vr-relaxation-will-almost-certainly-genre/). There is also work being done to treat various phobias in VR, and anecdotal evidence that VR has helped people become more comfortable in public speaking situations! I'm sure that medical uses of VR will continue to develop.    
Did you stress test Vive head tracking latency by tapping on the side or shaking your head?  How did it compare to DK2 and/or CB?
Great question. I was told by a Valve engineer that you could technically string Lighthouse stations together to cover extended spaces, so long as you uniquely identify each base station and of course configure/calibrate the space in some way. I doubt this is something we'll see available to most consumers (because it would be difficult to configure), but we may see it in specialized circumstances.  A seated experience should definitely still be viable, assuming you are not occluding the Lighthouse system. I think a combination would make for an incredible experience, like being able to fly your ship in [Elite Dangerous](https://www.youtube.com/watch?v=PUFIFL7zwXQ) and then get up and walk around the cabin!
They should be pretty equivalent since they're both doing [point-set registration](http://en.wikipedia.org/wiki/Point_set_registration) on a cloud of points (LEDs on the Crescent Bay, photodiodes on the Vive).  Lighthouse is interesting because it's doing point-set registration twice (once from each base); but the algorithm gets faster the better *starting position* you feed it, so the other base should have to do almost no alignment.  Plus, if one photodiode is visible to both, you can do stereo tracking (which is trivial computationally) which analytically constrains some of the points to make the point-set registration easier.   Plus, the lighthouse only updates at some 20hz or so; it's the IMUs in the headset and the controllers that bring it up to 100hz.
[13th Lab](http://youtu.be/e7bjsIqlbS0?t=1m5s) has done it pretty well...  but they're Oculus now.  CastAR doesn't have gyroscopic tracking integrated yet, but I suspect that that will help it acheive close to that level of cohesion.
Do you have a source for the 20 Hz number?
It appears that all the VR HMD companies are departing from the seated only experience mantra. As a gamer, I see the initial appeal of systems like the Virtuix Omni or the Virtualizer where you can run and duck etc. in VR.   That being said, as a gamer, I tend to enjoy sitting in my couch or computer chair and move minimally. Do you think the trend of video games development will continue to be designed around the seated experience? I really hope developers do not integrate required movement in VR games. I could see having to get up every 5 minutes to look at something in the corner of my room detracting from the experience.
'Pretty well' for sure, but the positional tracking needed for the head must be highly precise, sub-mm. They will continue to work on this of course, but it's definitely a challenge! Carmack said at GDC that Tango didn't have the necessary accuracy at this point (to be fair, Tango isn't quite aiming at VR at the moment). 
Ben, some of the best moments of presence for me is when I maximize the camera space of the DK2 and walk around a scene. Some of my favorites to do this in are from this link using Unreal demo scenes http://www.roadtovr.com/download-13-beautiful-unreal-engine-4-demos-oculus-rift-dk2/   I can't even imagine what it must be like to walk around a whole room, completely tracked regardless of direction. Can you maybe explain a bit more what that feels like? I imaging you must completely forget about real space when interacting with the environment. I am very excited to use this in social vr apps where you are literally mingling with others in a room...that's a whole new level! This is going to take social interaction to a whole new level.  There just seems to be a big step between moving around and avatar with a gamepad to being able to literally physically walk around a space with others.  Things like group therapy, etc would be a no brainer at this point.    EDIT: This was just posted on /r/oculus "When the headset came off, I had a very primal need to get back into VR. I didn't want to get back into VR, I needed to. Something was compelling me. I noticed it right away as foreign and was a bit confused about how a VR experience can ilicit a drug like response" 
Yes they can definitely compete. I think they are holding out for something beyond what we've seen so far. After all, it should be trivial to track a controller using the existing camera/IR-LED approach, but I think haptics and robustness are a big concern for them.  I think the Story Studio stuff was spun incorrectly to suggest that Oculus is moving away from input. Oculus' CEO told me that the company is still completely focused on gaming and interactive experiences, and the film stuff was just another sector where VR will play out, and it just happened to be in the spotlight that week because of Sundance.  That said, input is *huge* for VR. Even before STEM was announced and long before Lighthouse debuted, the most immersive VR experiences I ever had to that point were those using the Razer Hydra. The question of input and Oculus is not if, but when. In my opinion, they would be at a major experiential disadvantage to launch the CV1 without input, assuming that both SteamVR and Morpheus have it.
It just like a little speaker (and the same haptic device in the steam box controllers (if you've tried those)).  While it's not like real haptics in the sense that it approximates real sensations, it is the highest *bandwidth* haptic device I've seen, in the sense that it can convey such a variety of feelings.
I'm pretty sure they're [class 3](http://i.imgur.com/TgfoRVj.jpg) or so, but because of the scanning and some other tricks, they're considered Class 1... just to be clear.
Glad to hear from a reader : ).  * November does seem reasonable given what's been demonstrated at GDC. However, I don't think there will be *major* differences between the dev kit and the consumer version, there just isn't much time. I do hope the ergonomics improve though. * In my opinion, Gear VR already fits the bill for a "decent, reasonable priced, mobile VR headset," though the price aspect is still on the high end of the spectrum (and only if you already own the Note 4, though they are expanding to more phones and will likely continue to do so steadily). I'm hoping we'll see mobile VR headsets of Gear VR quality floating around $99 within the next 12 months. * Voxelpaint looks like it would be much better suited for a VR system with input, as drawing with your head/face is not terribly natural ; ). I would love to see something like this in SteamVR where you could literally build a house around yourself! Also, take a look at [Tilt Brush](http://www.tiltbrush.com/) by Skillman &amp; Hackett, they've been doing some really cool UI stuff which might be worth investigating.
Thanks for the answer. I think the perception of them moving away from input stems from them having all of these input free demos on CB. I don't think they've shown any interactive content on CB yet.  Thanks again for all of the coverage.
It's tough to say because almost none of these products have really hit the consumer market yet. Among the headsets, things are still in flux.  I think that Sony's Morpheus headset will probably be one of the best values to start (especially for existing PS4 owners), but that's assuming it comes in under $500 for the headset, camera, and controllers.  At this point, SteamVR has the best experience you'll find in a large tracking volume, and the finely tracked controllers are also important to both immersion and fun. So I have to say SteamVR for now, but again, we're going to see more from these companies before the launches start happening so things are in flux. It also depends on the experience you want. SteamVR will let you walk around a room, but you probably won't be sprinting anywhere. In that case, you might want a VR treadmill solution like the Cyberith Virtualizer or Virtuix Omni.  'Hear' is an interesting one. I believe that a combination of headphones and a chest-mounted 'thumper' will offer the best experience (when considering that you want to be able to 'feel' the sound no matter where you are standing within the space).  
Have you ever used the Tactical Haptics Reactive Grip? How do the linear motors in the Steam Controller/Lighthouse Controller compare to that?  I've seen it said that the Steam controller can simulate the tension of a bow string, just wondering if they are as powerful as the Reactive Grip's version of a similar thing or not.
Thank you very much! Conventions like GDC are a marathon, but it's great to hear that we're serving a need. I hope you got to go to the VR Mixer : ).  Road to VR started as a side project from other tech journalism (mostly focused on mobile technology) but as it grew it eventually became my full time job. I'm extremely fortunate to be working in such an exciting field of technology.
[Yes.](http://www.roadtovr.com/ces-2015-everything-need-know-3dhead-oculus-killer-headset/)  [Further reading, and one of the most interesting interviews I've ever done.](http://www.roadtovr.com/3dhead-oculus-killer-interview-ces-2015-james-jacobs/)
Nice! Even more excited about them, now.  Some will disagree, but I'm personally predicting CV1 will be substantially more advanced than the consumer Vive HMD (not counting external tracking). If Oculus doesn't manage at least a good control method, though, it's really looking like Valve will provide a substantially more advanced overall experience (except in seated sims with wheels or joysticks, and perhaps some things like Lucky's Tale).  If that situation does come about, perhaps someone might make a Lighthouse tracking module designed to be stuck to the Rift... I guess it's unlikely that CV1 will still have a convenient USB port on the headset, unfortunately.
pretty sure the dev that sold it would be sued into oblivion 
Yes, I prefer the horizon test (essentially nodding your head and seeing if the horizon stays where it should). SteamVR is rock solid on latency. The world feels incredibly Present, thanks to a combination of excellent latency, the ability to move through that world, and the ability to reach out and interact with it.  Crescent Bay's tracking performance is just as good. Even on the DK2 it's solid, provided you are running at the right frame rate.  20ms or less is the oft-quoted threshold for creating a world that feels completely solid around you. Whatever the value may be, SteamVR/Rift/Morpheus/Gear have all hit it for me. 
[deleted]
[deleted]
Which one is the most immersive among Vive, Oculus, and Morpheus?
Great question. I will send one back at you: have you used standing VR experiences?  For productivity and efficiency, I think we will still want to sit. For entertainment, I think that moving and reaching into the virtual world will be the best experience, but not necessarily the only one.  The way we play games (and the games we play) today (sitting on the couch, using primarily finger movements to control) is largely defined by the platforms that have been adopted, not necessarily the ultimate desires of gamers. Think about people who play racquetballdo they wish that they could play it on a screen sitting on their couch, using nothing but a controller? Of course not! Playing games on a couch with a controller (or chair with a KB/mouse) is probably just what more people are used to, but not necessarily what they want (even if they don't know if yet).  Now that this tech, which enables us to walk around and interact with virtual spaces, is about to drop, we'll have to wait and see what kind of demand there is for moving experiences vs. seated/static ones.  Personally, the idea of bringing physicality to games excites me (I always use the example of running a flag with 10 seconds left in a CGF game, and *really* having to sprint all out to win the game). And let's not forget about the health benefits
An educated estimate combined with looking into the lighthouse box when I tried the demo (you can see the little light spinning around in there; if it was spinning at 6k rpm, I wouldn't have been able to see anything spinning at all due to persistence of vision).  Plus, Valve talked about needing only a "few hz optical" + IMU a while ago (but I can't find that).  However, Carmack repeated it on twitter a year ago: https://twitter.com/ID_AA_Carmack/status/380111322353905665  This was around the same time that Valve and Oculus were sharing information rather closely (even loaning one of their "Valve Room" demos); I'm pretty sure the source of that nugget of wisdom was Valve.
SteamVR is the most immersive VR experience I've had to date, thanks in huge part to the space and the controllers. The HTC Vive is not any better than Crescent Bay (and is even less comfortable!), but having those other factors makes a world of difference.   The ability to see 3D is important to mapping the world around us. Our brain makes a model of what's there and considers it even when we aren't looking (ever walked to the top of your stairs and thought there was one more and get that funny feeling of stomping hard on the floor as you missed the invisible step?), that's the brain making use of it's mental map (incorrectly in this case). Being able to walk around an environment, like in SteamVR, allows you to build that mental map in a very natural way that's highly immersive.  And yes, you can forget about the real world around you once you gain confidence in the tracking system and 'Chaperone' which is what Valve calls their system that pops up a grid-like pattern within the virtual world if you are nearing a real wall.  The only think that kept me from becoming lost in the virtual space entirely was the cable attached to the headset which would occasionally get around my feet.
What was the screen like in the SteamVR demos? Did you notice any persistence blur? Do you know if it's an OLED or LCD?
Yes I've tried Tactical Haptics, and for certain virtual experiences, it works very well. The sliders are surprisingly powerful, even on the battery-powered wireless version, able to move again my hand even when gripping tightly.  SteamVR controller haptics are a combination of clicks and rumble, and they have been used well so far. I would still love to see Tactical Haptics tech built in there though, especially for picking up objects, pulling levers, swinging swords, etc.
What is your opinion on "other" HMDs like Razer OSVR?
I think it's due to how the laser from the class 3 device is handled before leaving the device.
I think it's because Tango relies too heavily on their (low resolution) depth map and not enough on their high resolution color camera and IMU (they're where you'll get your precision).  13th Lab figured out IMU+monoscopic camera stuff, as has Valve (who had been demoing their own inside-out tracking demo a little while ago).
Hmm... good question. It would require a cobling of systems, but should technically be able to attach a Lighthouse sensor array to an Oculus Rift. Valve has said that you can extend Lighthouse tracking to anything, provided you attach a sensor array to it. We'll have to see how much those eventually cost, but I was told that they envision a poker-chip sized sensor that runs on a watch battery.
Maybe not, plenty of Rifts have been sold on Ebay.
Yes it's definitely an oversimplification.   The supposed sweatshops are another good example of this sort of thinking. We walk around with smartphones in our pockets but we don't personally know any of the people making them. Sure, maybe we've heard stories of bad conditions here and there, but does it really cross our minds when we use our phones? It might if we could feel physically near those people.
[deleted]
All three have the same excellent level of tracking performance, but Vive takes the cake if we consider the tracking volume and the interactivity and robustness of the controllers. I [elaborated on my time with the system here](http://www.roadtovr.com/valve-steamvr-htc-vive-hands-on-gdc-2015-stage-constant-presence/).
The vast majority of those falling into the 'other' category have not demonstrated the same tracking performance as the big guys. The foundation of a great VR experience is the headset, and you need high quality rotational and positional tracking at very low latency to have a great headset (let's call Gear VR 'good' as it lacked positional tracking, but still offers a pretty compelling experience). Until you can achieve that, it doesn't really matter what kind of vR experience you are showing because the experience is likely to be very uncomfortable for the user.  In due time, I think all of the other headsets will achieve the same quality tracking and will hopefully offer some unique selling points.
I believe it is OLED with a PenTile structure. I didn't notice any blur beyond what I'm familiar with from DK2/Crescent Bay. IIRC I didn't see any black smear on the Vive which is very present on DK2. The resolution is getting quite good, you can still see that the image is made of pixels if you focus on it, but when you are concentrating on the virtual world around you, your brain neglects to care much, especially as that world becomes more immersive, as it is quite so in SteamVR.
What info do you have on VR outside North-America and Europe? Any teams working on exiting stuff? Any word from the big players about worldwide distribution and localized content?
I've only tried an early Oculus devkit, but I was disappointed to discover that the screen doesn't fully extend to the edges of peripheral vision.   It was impressive, but still felt kind of like wearing a scuba mask, with a fuzzy black ring around my vision.   Does anything that's been presented have truly complete field of view, such that you could hold your head still, move your eyes as far as possible in any direction and see nothing but screen?
The Valve stuff is a bit of a cheat because the fiducial markers make things very easy! Unless you're referring to something else?  I hope we get there. Consistent sub-mm tracking from CV would be huge for VR and many industries beyond it!
Aside from the "Big 3", Oculus, Steam, and Sony, are there any others that stand out among the pack? Or do you get the same feeling I do when I see these other VR headset companies come out with products/dev kits. It seems like they heard about VR, saw what the initiators were doing and thought, "Hey we can do that!" and then went on to release a product based on prototypes and iterations of other companies. Not realizing that these were the stepping stones to something great and not the finish line. Putting the headset (not final or 100% ideal) before the content to try and make a buck.
I'm not sure what I expected the COO of 3d Head to sound like, but in no way was I expecting him to have a southern accent.
The latest headsets from the big companies improve on the field of view, but none cover the entire field of view.  A few prototypes have been made as described, [InfinitEye](http://www.roadtovr.com/infiniteeye-worlds-first-ever-hands-210-fov-hmd-video/) is one, but haven't neared production. It's a very difficult challenge to make light come from all around you when you're dealing with a near-eye display.
Great question.  There are many out there as you have described (don't really seem to 'get' what it takes for a truly good experience). [OSVR's HDK](http://www.osvr.com/hardware.html) gives me hope. It isn't there yet (still in development), but I've been watching as it evolves, and I hope that the community at large can help build it up to something that offers an open platform upon which others can build.   It's a very exciting idea because there are many additions you might want to a headset, and people who may be willing to make them, but they have to solve the entire headset before even beginning work on that addition, they'll just be dragging themselves through a bunch of work that may not be even be their field of expertise.
https://twitter.com/vk2zay/status/573408108774477824
I have a question more content related, kind of two-fold. What are your top 5, or 10 experiences that you've had on any system so far? And secondly what are your top 5 or 10 experiences that you use when demoing your Rift to others? I'm trying to get a good batch of things for bringing into the office for everyone and want to streamline it with as many awesome, simple and "working" demos as possible.  My current fave being BlazeRush.
Here's an answer from the [man himself](http://www.gamasutra.com/view/feature/199361/a_conversation_with_oculus_vr_.php?print=1):  &gt; It's a lot of different trade-offs. Optically, as you go past 100 degrees, there are a lot of limits of optics you run into, and it can't just be solved with clever design. They're just the hard limits of refractive optics, and it's very hard to get around those. You can greatly increase the size -- like, if you double the size of the panel, then you can get a little further, but you're not doubling the field of view for doubling the size of the panel. It's diminishing returns. You end up with a huge headset with a slightly improved field of view. There are a few tricks that I am trying that I think that are going to be able to pump the field of view up beyond even where we are right now.
Have you heard anything from any of the Vive demo developers how hard it was/is to port from Rift to Vive?  (purely the HMD part of course)
Same, same but for prioVR system. If you ever have tried it that is.  Can prioVR keep up with either for tracked input? 
The "fiducial markers" weren't actually being identified and recognized (and no prior calibration took place).  The "markers" just provided an ample amount of corners (which are the prime feature that these types of algorithms lock onto).  If they had a similarly busy wallpaper or star field type of environment, the tracking would theoretically work just as well.
Except if it's text. Would you say whatever optics/diffuser magic they use would help with text legibility in Elite Dangerous? (this one for both CB and Vive)
[deleted]
&gt;Not particularly. I can say that I didn't see any Oculus faces around the Valve booth when I was there, and by the end of GDC, [Carmack said they hadn't yet seen the system](https://twitter.com/ID_AA_Carmack/status/573985052876374019).  There was a followup to that tweet, and it turns out [Valve never offered a demo to the Oculus crew](https://twitter.com/ID_AA_Carmack/status/574304005964177410) (while Sony did, and they tried the Morpheus). They probably would have tried the Vive if given the opportunity.
&gt; I'll drop an explanation that I wrote up in a Magic Leap article (again not an expert here, and I'd be happy if someone points out any misunderstandings from this text!)  Magic Leap is not using light field technology. They're using scanning fiber displays with piezoelectric actuators (to overcome the pixel size limit of other display technologies) and zone plate diffraction patterning devices.  Basically these are flat dynamic lenses that operate at 720 Hz (for 60 Hz displays) and can modify the distance of focus (12 discrete layers, from 0.25 to 3 m) to create an accommodation response from the eye.  This doesn't require a 1/10 resolution hit like light field displays but it still allows near correct accommodation cues. 
This right here is the biggest piece of info offered in this AMA.  Awesome to hear.
Valve's kit will be more along the lines of a proper dev kit... you will probably need to sign a contract to get one and even then it will remain the property of Valve/HTC. 
Thank you, I'll have to read more into this. I do believe that regardless of the tech, they are using 'light fields' in the sense that they are trying to accurately recreate the photons as though they'd been reflected from an object in real space, correct?
With their technology they don't need light fields, although they could use them for rendering like with the Rift. They only need a stereoscopic image and depth information for each pixel.
That sounds interesting. Do you have examples of these kind of screens?
Sorry, just double-checking there was no miscommunication since someone else just told me they noticed feedback only for their thumb: Are you saying some of the feedback seemed to affect the controller generally, not only the thumb touchpads? Thanks again. 
It was both, there was a nice localized clicking feeling under the touchpad and also a buzzing that could be applied more broadly.
Being able to get out of you pilot chair in ED would be awesome!  Maybe teleporting to a bar on the space station would make ED seem less lonely.
Recommended reading: http://www.amazon.com/Infinite-Reality-Hidden-Blueprint-Virtual/dp/0061809519/ref=sr_1_8?s=books&amp;ie=UTF8&amp;qid=1426263283&amp;sr=1-8&amp;keywords=virtual+reality
&gt; The way we play games (and the games we play) today (sitting on the couch, using primarily finger movements to control) is largely defined by the platforms that have been adopted, not necessarily the ultimate desires of gamers.  This!  
